"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.tokenize = tokenize;
const moo_1 = __importDefault(require("moo"));
// const show = (obj: any): string => JSON.stringify(obj, null, 2).replace(/[\u007F-\uFFFF]/g, chr => `\\u${(`0000${chr.charCodeAt(0).toString(16)}`).substr(-4)}`)
const rx = __importStar(require("./re"));
const L = rx.match(rx.categories.filter(cat => cat.name === 'L'));
const LNM = rx.match(rx.categories.filter(cat => cat.name.match(/^[LNM]/)), '\u00AD\u2060');
const W = `${LNM}*?${L}${LNM}*`;
const B = `(?=(?:${rx.match(rx.categories.filter(cat => cat.name.match(/^[LNM]/)), '\u00AD\u2060').replace(/^./, '[^')}|$))`;
const Word = new RegExp(`${W}${B}`);
const P = new RegExp(rx.match(rx.categories.filter(cat => cat.name.match(/^P/))));
const Lu = rx.match(rx.categories.filter(cat => cat.name === 'Lu' || cat.name === 'Lt'), '\u2060');
const Acronym = new RegExp(`(?:(?:(?:${Lu}[.]){2,}${B})|(?:(?:vs?[.])(?=[ \t\n\r\u00A0])))`);
const Contraction = new RegExp(`${W}['’]${W}${B}`);
const Whitespace = /[ \t\n\r\u00A0]+/;
const Ordinal = new RegExp(`\\d+(?:st|nd|rd|th)${B}`);
const Email = new RegExp(`[A-Za-z0-9._%+-]+@[A-Za-z0-9-]+(?:[.][A-Za-z0-9-]+)+${B}`);
const Handle = new RegExp(`@[A-Za-z0-9-]{2,}${B}`);
const IntOrVersion = new RegExp(`v?\\d+(?:\\.\\d+)*${B}`);
const Domain = new RegExp(`${W}(?:[.]${W})+${B}`);
const Website = new RegExp(`https?://${W}(?:[.]${W})+(?:[^.!? \t\n\r\u00A0]+|[.!?]${LNM})+`);
const ComplexPreposition = /^([^ \t\n\r\u00A0]+)([ \t\n\r\u00A0]+)([^ \t\n\r\u00A0]+)(?:([ \t\n\r\u00A0]+)([^ \t\n\r\u00A0]+))?$/;
function ci(s) {
    return s
        .replace(/[a-z]/ig, match => `[${match.toUpperCase()}${match.toLowerCase()}]`)
        .replace(' ', Whitespace.source);
}
const prepositions = require('./prepositions.json').sort().reverse().map(ci).join('|');
const Preposition = new RegExp(`(?:${prepositions})${B}`);
const lexer = moo_1.default.compile({
    'word-preposition': Preposition,
    'word-acronym': Acronym,
    'word-contraction': Contraction,
    'word-ordinal': Ordinal,
    email: Email,
    handle: Handle,
    website: Website,
    domain: Domain,
    word: Word,
    number: IntOrVersion, // eslint-disable-line id-blacklist
    'punctuation-end': /[?.!](?=[ \t\n\r\u00A0]|$)/,
    'punctuation-colon': /:(?=[ \t\n\r\u00A0])/,
    'punctuation-ellipsis': /[.][.][.]/,
    punctuation: P,
    whitespace: { match: /[ \t\n\r\u00A0]/, lineBreaks: true },
    other: { match: /[\s\S]/, lineBreaks: true },
});
const Shape = new class {
    constructor() {
        this.shapes = {};
        this.re = {
            X: new RegExp(rx.match(rx.categories.filter(cat => cat.name === 'Lu' || cat.name === 'Lt'))),
            x: new RegExp(rx.match(rx.categories.filter(cat => cat.name.match(/^L[^Cut]/)))),
            d: new RegExp(rx.match(rx.categories.filter(cat => cat.name[0] === 'N'))),
        };
    }
    match(c) {
        if (c.match(this.re.d))
            return 'd';
        if (c.toLowerCase() === c.toUpperCase())
            return c;
        if (c.match(this.re.X))
            return 'X';
        if (c.match(this.re.x))
            return 'x';
        if (c === '’')
            return "'";
        if (c === '–')
            return '-';
        if (c === '\u2060' || c === '\u00AD')
            return '';
        return c;
    }
    fetch(c) {
        if (typeof this.shapes[c] === 'undefined')
            this.shapes[c] = this.match(c);
        return this.shapes[c];
    }
    shape(t) {
        if (!this.shapes[t])
            this.shapes[t] = Array.from(t).map(c => this.fetch(c)).join('');
        return this.shapes[t];
    }
};
function combine(tokens) {
    const combined = Object.assign({}, tokens[0]);
    for (const t of tokens.slice(1)) {
        combined.text += t.text;
        combined.end = t.end;
        combined.shape += t.shape;
    }
    return combined;
}
function hyphenate(t) {
    if (t.type === 'word')
        return 'w';
    if (t.text === '-' || t.text === '–')
        return '-';
    return ' ';
}
function tokenize(title, markup) {
    if (markup)
        title = title.replace(markup, match => '\u2060'.repeat(match.length));
    lexer.reset(title);
    const tokens = [];
    let sentenceStart = true;
    let subSentenceStart = false;
    for (const token of lexer) {
        const [type, subtype] = (token.type.includes('-') ? token.type : `${token.type}-`).split('-');
        tokens.push({
            type, subtype,
            text: token.text,
            start: token.offset,
            end: token.offset + token.text.length - 1,
            shape: Shape.shape(token.text),
            sentenceStart: type === 'word' && sentenceStart,
            subSentenceStart: type === 'word' && subSentenceStart,
        });
        switch (token.type) {
            case 'punctuation-end':
                sentenceStart = true;
                break;
            case 'punctuation-colon':
                subSentenceStart = true;
                break;
            default:
                if (type.match(/word|number|handle|domain|website/)) {
                    sentenceStart = false;
                    subSentenceStart = false;
                }
                break;
        }
    }
    const stack = tokens.splice(0);
    let cpt;
    let cps;
    while (stack.length) {
        if (stack[0].subtype === 'preposition' && (cpt = stack[0].text.match(ComplexPreposition)) && (cps = stack[0].shape.match(ComplexPreposition))) {
            const complex = stack.shift();
            let start = complex.start;
            let end;
            for (const i of Array.from({ length: 5 }, (_, n) => n + 1)) {
                if (!cpt[i])
                    break;
                end = start + cps[i].length - 1;
                tokens.push(Object.assign(Object.assign({}, complex), { text: cpt[i], shape: cps[i], start,
                    end, type: i % 2 ? complex.type : 'whitespace', subtype: i % 2 ? complex.type : '' }));
                start = end + 1;
            }
            continue;
        }
        // hyphenated words
        const pat = stack.map(t => hyphenate(t)).join('');
        if (cpt = pat.match(/^w(-w)+(?= |$)/)) {
            const hyphenated = stack.splice(0, cpt[0].length);
            tokens.push(Object.assign(Object.assign({}, combine(hyphenated)), { hyphenated }));
            continue;
        }
        tokens.push(stack.shift());
    }
    return markup ? tokens.map(token => (Object.assign(Object.assign({}, token), { text: title.substring(token.start, token.end + 1) }))) : tokens;
}
//# sourceMappingURL=tokenizer.js.map